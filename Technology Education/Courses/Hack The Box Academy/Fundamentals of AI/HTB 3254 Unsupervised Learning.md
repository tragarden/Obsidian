# Unsupervised Learning

Unsupervised Learning is used to observe and explore unlabeled data to discover hidden patterns, structures, and relationships. This is done without the guidance of predefined labels or 'correct answers.' It is distinct from supervised learning where the goal is to predict outcomes.

You can think of unsupervised learning as looking at a new and unfamiliar map and making conclusions about items on the map.

These are particularly powerful methods when data is unavailable, rare, or expensive. It yields insights into the structure and organization of the data without observing outcomes.

There are three main categories for unsupervised learning:

- Clustering - when similar data points are grouped together by attributes or characteristics.
- Dimensionality Reduction - reducing the number of variables or features while preserving the essential information, akin to summarizing a text or compressing an image file.
- Anomaly Detection - identifying outlying data points and deviations from the observed norm. 

### Core Concepts

#### Unlabeled Data

Unsupervised Learning relies heavily on unlabeled data that is lacking in predicted outcomes. The model relies on characteristics of data instead of outcomes. 

#### Similarity Measures

Unsupervised Learning rely heavily on assessing and quantifying the level of similarity or dissimilarity between data points. 

Common methods for measuring similarity include:

- Euclidean Distance - the straight-line distance between two points.
- Cosine Similarity - the angle between two vectors with higher values representing increased similarity.
- Manhattan Distance - a calculation for distance where absolute difference between coordinates are summed.

#### Clustering Tendency

Clustering Tendency is the data's inherent nature to form clusters, before clustering algorithms are applied to the data. If the data is distributed in a uniform way, clustering algorithms may not benefit the results.

#### Cluster Validity

Cluster Validity evaluates the quality and impact of clusters generated by a clustering algorithm.

Metrics that are assessed at this stage include:

- Cohesion - how similar data points are within their cluster. High cohesion rates indicate well-defined clusters.
- Separation - how far clusters are from each other. High separation indicates distinct and well-separated clusters.

#### Dimensionality

Dimensionality is the number of features or variables that exist in the data set. When dimensionality is high there is a chance for increased computational complexity and what is known as the 'curse of dimensionality.'

The Curse of Dimensionality is when data becomes sparse and the distances between data pointes become less meaningful.

#### Intrinsic Dimensionality

Intrinsic Dimensionality refers to the inherent dimensionality of a set of data. It may be lower than the number of features within the set. Thi9s is meant to capture essential information from the data and when dimensionality reduction is implemented, the number of features is reduced while preserving intrinsic dimensionality.

#### Anomaly

An Anomaly is a data point that significantly deviates from the expected pattern or norms. They can represent unusual events, errors, or fraud. Anomaly detection is crucial in regard to fraud detection, network security, and system monitoring.

#### Outlier

An Outlier is a data point that is far away from the majority of other known points. They can be used as indicators of errors in data collection, unusual observations, and interesting patterns. 

#### Feature Scaling

Feature Scaling ensures that all features contribute equally to the distance calculations and computation algorithms.

Some techniques for achieving feature scaling include:

- Min-Max Scaling - scaling all features to a fixed range.
- Standardization (Z-Score) - transforms features to have zero mean and unit variance. 

### Related:
- [Hack The Box Academy](https://academy.hackthebox.com/ "Hack The Box Academy Home page")
- [HTB Unsupervised Learning](https://academy.hackthebox.com/module/290/section/3254 "HTB Unsupervised Learning")