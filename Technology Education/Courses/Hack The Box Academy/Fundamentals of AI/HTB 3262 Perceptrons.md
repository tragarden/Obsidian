# Perceptrons

A Perceptron is a simplified model of a neuron used in basic decision making. This is the fundamental component of deep learning and neural networks.

A Perceptron is composed of six key parts:

- Input Values - initial points of data representing features or attributes of the data.
- Weights - associated with each input value, determining importance or strength of the data point. They can be positive or negative and are used to influence output.
- Summation Function - weighted inputs are summed to aggregate the weighted inputs into a single value.
- Bias - added to the weighted sum in order to shift the activation function. This allows the perceptron to activate when all values are zero.
- Activation Function - introduced non-linearity into perceptrons by taking the weighted sum plus bias as input in order to produce output.
- Output - usually a binary value that indicates a decision or classification.

Note that perceptrons are limited by their inability to solve problems that are not linearly separable. 

Linearly Separable Data Sets are able to be divided into two categories by a single straight line or hyperplane.

### Related:
- [Hack The Box Academy](https://academy.hackthebox.com/ "Hack The Box Academy Home page")
- [HTB Perceptrons](https://academy.hackthebox.com/module/290/section/3262 "HTB Perceptrons")